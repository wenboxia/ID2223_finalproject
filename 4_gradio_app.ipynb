{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3e21c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Initialization: Fetching latest data and model...\n",
      "ü§ñ Connecting to Hopsworks to download model...\n",
      "2026-01-13 22:31:06,430 INFO: Initializing external client\n",
      "2026-01-13 22:31:06,430 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-13 22:31:07,071 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-13 22:31:08,071 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1303706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c46de5d0e34dceaba45c7c457f6fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/203984 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-13 22:31:11,097 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2026-01-13 22:31:11,097 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2026-01-13 22:31:11,098 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "‚úÖ Data ready!\n",
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "2026-01-13 22:31:11,302 INFO: HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:31:11,314 INFO: HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:31:11,332 INFO: HTTP Request: HEAD https://huggingface.co/api/telemetry/https%3A/api.gradio.app/gradio-initiated-analytics \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:31:11,849 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:31:12,013 INFO: HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "* Running on public URL: https://c6bf9cf023191d4b88.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "2026-01-13 22:31:13,718 INFO: HTTP Request: HEAD https://c6bf9cf023191d4b88.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c6bf9cf023191d4b88.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-13 22:31:13,861 INFO: HTTP Request: HEAD https://huggingface.co/api/telemetry/https%3A/api.gradio.app/gradio-launched-telemetry \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:31:35,112 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:31:35,831 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:31:36,122 INFO: HTTP Request: POST https://router.huggingface.co/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:31:52,697 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:31:53,065 INFO: HTTP Request: POST https://router.huggingface.co/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:31:53,969 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:32:04,254 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:32:04,556 INFO: HTTP Request: POST https://router.huggingface.co/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:32:05,494 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:32:26,895 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:32:27,377 INFO: HTTP Request: POST https://router.huggingface.co/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:32:28,442 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:32:45,466 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-13 22:32:46,114 INFO: HTTP Request: POST https://router.huggingface.co/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-13 22:32:46,909 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import hopsworks\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Set Hugging Face Token (if not in environment variables)\n",
    "if \"HF_TOKEN\" not in os.environ:\n",
    "    os.environ[\"HF_TOKEN\"] = \"HF_token\"\n",
    "\n",
    "# ==========================================\n",
    "#  Model Part: Fetch Weather & Predict Wind\n",
    "# ==========================================\n",
    "def get_weather_forecast():\n",
    "    # Fetch 7-day forecast (Same logic as File 3)\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": 39.4532, # Flores\n",
    "        \"longitude\": -31.1274,\n",
    "        \"daily\": [\"temperature_2m_max\", \"precipitation_sum\", \"wind_gusts_10m_max\", \"wind_direction_10m_dominant\"],\n",
    "        \"timezone\": \"Atlantic/Azores\",\n",
    "        \"forecast_days\": 7\n",
    "    }\n",
    "    \n",
    "    responses = openmeteo.weather_api(\"https://api.open-meteo.com/v1/forecast\", params=params)\n",
    "    response = responses[0]\n",
    "    daily = response.Daily()\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"date\": pd.date_range(\n",
    "            start = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "            end = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "            freq = pd.Timedelta(seconds = daily.Interval()),\n",
    "            inclusive = \"left\"\n",
    "        ),\n",
    "        \"temperature_max\": daily.Variables(0).ValuesAsNumpy(),\n",
    "        \"precipitation\": daily.Variables(1).ValuesAsNumpy(),\n",
    "        \"wind_gusts\": daily.Variables(2).ValuesAsNumpy(),\n",
    "        \"wind_direction\": daily.Variables(3).ValuesAsNumpy(),\n",
    "    })\n",
    "    df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "def get_prediction_summary():\n",
    "    \"\"\"\n",
    "    Run the ML model and return a text summary of the 7-day wind forecast.\n",
    "    \"\"\"\n",
    "    print(\" Connecting to Hopsworks to download model...\")\n",
    "    try:\n",
    "        project = hopsworks.login()\n",
    "        mr = project.get_model_registry()\n",
    "        # Note: Loading the new wind model\n",
    "        model = mr.get_model(name=\"azores_wind_model\", version=1)\n",
    "        model_dir = model.download()\n",
    "        \n",
    "        model_path = os.path.join(model_dir, \"azores_wind_model.pkl\")\n",
    "        trained_model = joblib.load(model_path)\n",
    "        \n",
    "        df = get_weather_forecast()\n",
    "        features = df[['temperature_max', 'precipitation', 'wind_gusts', 'wind_direction']]\n",
    "        \n",
    "        preds = trained_model.predict(features)\n",
    "        \n",
    "        summary = \"\"\n",
    "        for date, wind, gust in zip(df['date_str'], preds, df['wind_gusts']):\n",
    "            wind_kmh = max(0, wind)\n",
    "            summary += f\"- {date}: Predicted Wind {wind_kmh:.1f} km/h (Gusts {gust:.1f} km/h)\\n\"\n",
    "        \n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"Failed to fetch prediction data: {str(e)}\"\n",
    "\n",
    "# Pre-load data during initialization\n",
    "print(\"Initialization: Fetching latest data and model...\")\n",
    "CACHE_FORECAST = get_prediction_summary()\n",
    "print(\"Data ready!\")\n",
    "\n",
    "# ==========================================\n",
    "# LLM Part: Define Persona and Logic\n",
    "# ==========================================\n",
    "def chatbot_response(message, history):\n",
    "    # Initialize HF Client\n",
    "    client = InferenceClient(\n",
    "        \"Qwen/Qwen2.5-7B-Instruct\", \n",
    "        token=os.environ[\"HF_TOKEN\"]\n",
    "    )\n",
    "    \n",
    "    # System Prompt - Define persona as 'Captain Joao'\n",
    "    system_prompt = f\"\"\"\n",
    "    You are 'Captain Joao', an experienced and humorous speedboat captain in Flores, Azores.\n",
    "    Your job is to take tourists to the neighboring Corvo Island.\n",
    "    \n",
    "    Here is the REAL wind forecast for the next 7 days (based on ML predictions):\n",
    "    {CACHE_FORECAST}\n",
    "    \n",
    "    **Rules:**\n",
    "    1. Answer based on the data above.\n",
    "    2. If predicted wind > 30 km/h: Be apologetic and warn that the boat is cancelled due to high waves. Suggest wine instead.\n",
    "    3. If predicted wind < 30 km/h: Be cheerful and say it's a perfect day for sailing!\n",
    "    4. Keep answers short, nautical, and use emojis like üåä, üö§, ‚öì, üå¨Ô∏è.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    # Append history\n",
    "    messages.extend(history)\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # Stream the response\n",
    "    partial_message = \"\"\n",
    "    try:\n",
    "        for token in client.chat_completion(messages, max_tokens=500, stream=True):\n",
    "            if token.choices[0].delta.content:\n",
    "                partial_message += token.choices[0].delta.content\n",
    "                yield partial_message\n",
    "    except Exception as e:\n",
    "        yield f\" Error: {str(e)}\"\n",
    "\n",
    "# ==========================================\n",
    "#  Gradio Interface\n",
    "# ==========================================\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot_response,\n",
    "    title=\"üö§ Flores-Corvo Boat Forecaster\",\n",
    "    description=\"Architecture: Gradient Boosting Wind Prediction + LLM (Qwen-2.5)\",\n",
    "    examples=[\n",
    "        \"Will the boat run tomorrow?\",\n",
    "        \"Is the weather good for sailing this weekend?\",\n",
    "        \"What if the wind is too strong?\",\n",
    "    ],\n",
    "    cache_examples=False\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
